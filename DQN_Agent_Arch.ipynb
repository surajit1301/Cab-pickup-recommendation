{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VYk5htm6lWSL"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5r17J7cqlWSP"
   },
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d1Ru_HualWSS"
   },
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58aY67CzlWSU",
    "outputId": "9c648cca-ed05-4ec7-c65c-bb49bc55710a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 24, 7)\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "print(Time_matrix.shape)\n",
    "print(Time_matrix[3][2][17][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HntuGDRGlWSX"
   },
   "source": [
    "It means the time required to travel from city 3 to city 2 at 17 hrs and 5th day of the week is 8 time units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avq4uRsllWSX",
    "outputId": "80388e92-af49-4fe1-e4e9-14c8bf8d18cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimimum time taken: 0.0\n",
      "Maximum time taken: 11.0\n",
      "Average time taken: 3.0542857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimimum time taken:\", Time_matrix.min())\n",
    "print(\"Maximum time taken:\", Time_matrix.max())\n",
    "print(\"Average time taken:\", Time_matrix.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asfAtoY6lWSY"
   },
   "source": [
    "### Checking if the environment is responding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOm3hR2hlWSZ",
    "outputId": "a601aba6-df5f-41b1-85c9-49c7015f0c93",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State Initialization:\n",
      "Episode 0 (1, 1, 2)\n",
      "Episode 1 (2, 4, 2)\n",
      "Episode 2 (2, 13, 1)\n",
      "Episode 3 (1, 18, 2)\n",
      "Episode 4 (2, 10, 4)\n"
     ]
    }
   ],
   "source": [
    "from Env import CabDriver \n",
    "print(\"Random State Initialization:\")\n",
    "for i in range(5):         ## Checking for 5 epsiodes\n",
    "    env= CabDriver()\n",
    "    random_state_init= env.state_init\n",
    "    print(f'Episode {i}', random_state_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHZpperIlWSZ"
   },
   "source": [
    "In episode 0, the cab is in 2nd city at 8 hrs and 6th day of week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGtESFDolWSa"
   },
   "source": [
    "### Checking the action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aX_nBT3ylWSa",
    "outputId": "10b64a0a-a9f1-4e61-c2b9-f62bb457d6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all possible actions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, (0, 0)),\n",
       " (1, (0, 1)),\n",
       " (2, (0, 2)),\n",
       " (3, (0, 3)),\n",
       " (4, (0, 4)),\n",
       " (5, (1, 0)),\n",
       " (6, (1, 2)),\n",
       " (7, (1, 3)),\n",
       " (8, (1, 4)),\n",
       " (9, (2, 0)),\n",
       " (10, (2, 1)),\n",
       " (11, (2, 3)),\n",
       " (12, (2, 4)),\n",
       " (13, (3, 0)),\n",
       " (14, (3, 1)),\n",
       " (15, (3, 2)),\n",
       " (16, (3, 4)),\n",
       " (17, (4, 0)),\n",
       " (18, (4, 1)),\n",
       " (19, (4, 2)),\n",
       " (20, (4, 3))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating tuples of action_index and actions from action_space\n",
    "from Env import CabDriver\n",
    "env= CabDriver()\n",
    "cab_action_space = env.action_space\n",
    "cab_action_indices =[i for i in range(len(cab_action_space))]\n",
    "action_list= [i for i in zip(cab_action_indices, cab_action_space)]   ## tuples (action_indices, action)\n",
    "print(\"List of all possible actions\")\n",
    "action_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppOLv9QXlWSb"
   },
   "source": [
    "Since we are doing Q-learning, the network will learn a deterministric policy. Given a state, there is only one favourable action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4IUwChClWSb"
   },
   "source": [
    "### Creating the agent who will experience things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VlNbAIQClWSc"
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self, state_size, action_size, \n",
    "                 discount_factor=0.95, learning_rate=0.01,\n",
    "                 epsilon=1, epsilon_decay=0.99, epsilon_min=0.01):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        \n",
    "        # Create replay memory using deque\n",
    "        self.memory = deque(maxlen = 3000)\n",
    "        \n",
    "        # Initialize the value of the states tracked for all samples\n",
    "        self.states_tracked = []\n",
    "        \n",
    "        # Initializing a tracker to check learning\n",
    "        # We will track state (2,8,6) and action (2,3) during training\n",
    "        self.track_state = np.array(env.state_encod_arch((2,8,6))).reshape(1, self.state_size)\n",
    "        \n",
    "        # Create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Takes in the agent and constructs a neural network to train it and returns model and parameters.\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_dim= self.state_size, activation= 'relu'))\n",
    "        model.add(Dense(32, activation= 'relu'))\n",
    "        model.add(Dense(self.action_size, activation='relu'))\n",
    "        \n",
    "        # Compile Model\n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        \n",
    "        '''\n",
    "        Choose an action from action space using epsilon greedy policy\n",
    "        Decay in Îµ after we generate each sample during an episode\n",
    "        '''\n",
    "        possible_actions_index, actions= env.requests(state)\n",
    "        \n",
    "        # get action from model using epsilon-greedy policy\n",
    "        z = np.random.rand()  ## variable z randomly chooses a value between [0,1)\n",
    "        if z <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            state = np.array(env.state_encod_arch(state)).reshape(1, self.state_size)\n",
    "            q_vals = self.model.predict(state)\n",
    "            q_vals_possible = np.array([q_vals[0][i] for i in possible_actions_index])\n",
    "            \n",
    "            ## Choosing the action corresponding to highest q-value\n",
    "            return possible_actions_index[np.argmax(q_vals_possible)] \n",
    "        \n",
    "    def append_sample(self, state, action_index, reward, next_state, done):\n",
    "        '''\n",
    "        Append the new agent run output to replay buffer\n",
    "        '''\n",
    "        self.memory.append((state, action_index, reward, next_state, done))\n",
    "        \n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\" \n",
    "        Function to train the model on each step run.\n",
    "        Pick random memory events according to batch size and \n",
    "        runs it through the network to train it.\n",
    "        \"\"\"\n",
    "      \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            \n",
    "            ## Initializing the trackers\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            actions, rewards, done = [], [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, done_boolean = mini_batch[i]\n",
    "                update_input[i] = env.state_encod_arch(state)     \n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = env.state_encod_arch(next_state)\n",
    "                done.append(done_boolean)\n",
    "                \n",
    "            target = self.model.predict(update_input)\n",
    "            target_qval = self.model.predict(update_output)\n",
    "\n",
    "            # update the target values\n",
    "            for i in range(self.batch_size):\n",
    "                if done[i]:      #terminal state\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else:            # non-terminal state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "             \n",
    "            # model fit\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "    \n",
    "    \n",
    "    def save_tracking_states(self):\n",
    "        '''\n",
    "        Use the model to predict the q_value of the state we are tacking.\n",
    "        '''\n",
    "        q_value_1 = self.model.predict(self.track_state)\n",
    "        self.states_tracked.append(q_value_1[0][11])    ## action (2,3) at index 11 in the action space\n",
    "        \n",
    "        \n",
    "    def save_model_weights(self, name): ## Saves the weights in Keras format\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "        \n",
    "    def save_weights_numpy(self, name):      ## Saves the 'model_weights' in a  pickle file\n",
    "        weights= self.model.get_weights()   ## Gets model_weights as a list of numpy arrays\n",
    "        try:\n",
    "            fpkl= open(name, 'wb')\n",
    "            pickle.dump(weights, fpkl, protocol= pickle.HIGHEST_PROTOCOL)  \n",
    "            fpkl.close()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    def save(self, name):  ## Saves the model in H5 format\n",
    "        self.model.save(name) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O5w44r1lWSk"
   },
   "source": [
    "### Preparing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nX7NOfv2lWSk",
    "outputId": "1643dbcb-01e5-4f00-a903-4fec5547e6b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "episode_time = 24*30   \n",
    "Episodes = 1000       \n",
    "m = 5                  \n",
    "t = 24                 \n",
    "d = 7                  \n",
    "\n",
    "# Invoke Env class\n",
    "env = CabDriver()\n",
    "action_space, state_space, state = env.reset()\n",
    "\n",
    "# Set up state and action sizes.\n",
    "state_size = m+t+d\n",
    "action_size = len(action_space)\n",
    "\n",
    "# Invoke agent class (Parameters kept same as lectures and no tuning is done)\n",
    "agent = DQNAgent(action_size=action_size, \n",
    "                 state_size=state_size,\n",
    "                 discount_factor=0.95, \n",
    "                 learning_rate=0.01,\n",
    "                 epsilon=1, \n",
    "                 epsilon_decay=0.99, \n",
    "                 epsilon_min=0.01)\n",
    "\n",
    "# to store rewards in each episode\n",
    "rewards_per_episode, episodes = [], []\n",
    "# Rewards for state\n",
    "rewards_init_state = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-XwWsnnlWSl"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17Kcv1QKlWSl",
    "outputId": "3886640f-4840-4e49-e12a-a91227724e76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0\n",
      "Saving Episode 0 Weights\n",
      "Episode  1\n",
      "Episode  2\n",
      "Episode  3\n",
      "Episode  4\n",
      "Episode  5\n",
      "Episode  6\n",
      "Episode  7\n",
      "Episode  8\n",
      "Episode  9\n",
      "episode 9, initial_state (4, 3, 5), reward -31.0, memory_length 1165, epsilon 0.9043820750088043 total_time 722.0\n",
      "Episode  10\n",
      "Episode  11\n",
      "Episode  12\n",
      "Episode  13\n",
      "Episode  14\n",
      "Episode  15\n",
      "Episode  16\n",
      "Episode  17\n",
      "Episode  18\n",
      "Episode  19\n",
      "episode 19, initial_state (1, 14, 3), reward 387.0, memory_length 2322, epsilon 0.8179069375972307 total_time 724.0\n",
      "Episode  20\n",
      "Episode  21\n",
      "Episode  22\n",
      "Episode  23\n",
      "Episode  24\n",
      "Episode  25\n",
      "Episode  26\n",
      "Episode  27\n",
      "Episode  28\n",
      "Episode  29\n",
      "episode 29, initial_state (2, 20, 1), reward 95.0, memory_length 3000, epsilon 0.7397003733882802 total_time 728.0\n",
      "Episode  30\n",
      "Episode  31\n",
      "Episode  32\n",
      "Episode  33\n",
      "Episode  34\n",
      "Episode  35\n",
      "Episode  36\n",
      "Episode  37\n",
      "Episode  38\n",
      "Episode  39\n",
      "episode 39, initial_state (1, 17, 4), reward 321.0, memory_length 3000, epsilon 0.6689717585696803 total_time 721.0\n",
      "Episode  40\n",
      "Episode  41\n",
      "Episode  42\n",
      "Episode  43\n",
      "Episode  44\n",
      "Episode  45\n",
      "Episode  46\n",
      "Episode  47\n",
      "Episode  48\n",
      "Episode  49\n",
      "episode 49, initial_state (3, 1, 5), reward 184.0, memory_length 3000, epsilon 0.6050060671375365 total_time 721.0\n",
      "Episode  50\n",
      "Episode  51\n",
      "Episode  52\n",
      "Episode  53\n",
      "Episode  54\n",
      "Episode  55\n",
      "Episode  56\n",
      "Episode  57\n",
      "Episode  58\n",
      "Episode  59\n",
      "episode 59, initial_state (3, 8, 0), reward -67.0, memory_length 3000, epsilon 0.5471566423907612 total_time 727.0\n",
      "Episode  60\n",
      "Episode  61\n",
      "Episode  62\n",
      "Episode  63\n",
      "Episode  64\n",
      "Episode  65\n",
      "Episode  66\n",
      "Episode  67\n",
      "Episode  68\n",
      "Episode  69\n",
      "episode 69, initial_state (2, 3, 1), reward 468.0, memory_length 3000, epsilon 0.49483865960020695 total_time 723.0\n",
      "Episode  70\n",
      "Episode  71\n",
      "Episode  72\n",
      "Episode  73\n",
      "Episode  74\n",
      "Episode  75\n",
      "Episode  76\n",
      "Episode  77\n",
      "Episode  78\n",
      "Episode  79\n",
      "episode 79, initial_state (4, 2, 2), reward 570.0, memory_length 3000, epsilon 0.44752321376381066 total_time 725.0\n",
      "Episode  80\n",
      "Episode  81\n",
      "Episode  82\n",
      "Episode  83\n",
      "Episode  84\n",
      "Episode  85\n",
      "Episode  86\n",
      "Episode  87\n",
      "Episode  88\n",
      "Episode  89\n",
      "episode 89, initial_state (4, 2, 4), reward 546.0, memory_length 3000, epsilon 0.4047319726783239 total_time 722.0\n",
      "Episode  90\n",
      "Episode  91\n",
      "Episode  92\n",
      "Episode  93\n",
      "Episode  94\n",
      "Episode  95\n",
      "Episode  96\n",
      "Episode  97\n",
      "Episode  98\n",
      "Episode  99\n",
      "episode 99, initial_state (4, 11, 2), reward 326.0, memory_length 3000, epsilon 0.36603234127322926 total_time 721.0\n",
      "Episode  100\n",
      "Episode  101\n",
      "Episode  102\n",
      "Episode  103\n",
      "Episode  104\n",
      "Episode  105\n",
      "Episode  106\n",
      "Episode  107\n",
      "Episode  108\n",
      "Episode  109\n",
      "episode 109, initial_state (4, 4, 4), reward 258.0, memory_length 3000, epsilon 0.33103308832101386 total_time 728.0\n",
      "Episode  110\n",
      "Episode  111\n",
      "Episode  112\n",
      "Episode  113\n",
      "Episode  114\n",
      "Episode  115\n",
      "Episode  116\n",
      "Episode  117\n",
      "Episode  118\n",
      "Episode  119\n",
      "episode 119, initial_state (0, 16, 4), reward 693.0, memory_length 3000, epsilon 0.29938039131233124 total_time 722.0\n",
      "Episode  120\n",
      "Episode  121\n",
      "Episode  122\n",
      "Episode  123\n",
      "Episode  124\n",
      "Episode  125\n",
      "Episode  126\n",
      "Episode  127\n",
      "Episode  128\n",
      "Episode  129\n",
      "episode 129, initial_state (1, 17, 2), reward 560.0, memory_length 3000, epsilon 0.270754259511994 total_time 722.0\n",
      "Episode  130\n",
      "Episode  131\n",
      "Episode  132\n",
      "Episode  133\n",
      "Episode  134\n",
      "Episode  135\n",
      "Episode  136\n",
      "Episode  137\n",
      "Episode  138\n",
      "Episode  139\n",
      "episode 139, initial_state (1, 11, 1), reward 903.0, memory_length 3000, epsilon 0.24486529903492946 total_time 727.0\n",
      "Episode  140\n",
      "Episode  141\n",
      "Episode  142\n",
      "Episode  143\n",
      "Episode  144\n",
      "Episode  145\n",
      "Episode  146\n",
      "Episode  147\n",
      "Episode  148\n",
      "Episode  149\n",
      "episode 149, initial_state (2, 8, 1), reward 518.0, memory_length 3000, epsilon 0.22145178723886094 total_time 729.0\n",
      "Episode  150\n",
      "Episode  151\n",
      "Episode  152\n",
      "Episode  153\n",
      "Episode  154\n",
      "Episode  155\n",
      "Episode  156\n",
      "Episode  157\n",
      "Episode  158\n",
      "Episode  159\n",
      "episode 159, initial_state (1, 0, 6), reward 947.0, memory_length 3000, epsilon 0.20027702685748935 total_time 724.0\n",
      "Episode  160\n",
      "Episode  161\n",
      "Episode  162\n",
      "Episode  163\n",
      "Episode  164\n",
      "Episode  165\n",
      "Episode  166\n",
      "Episode  167\n",
      "Episode  168\n",
      "Episode  169\n",
      "episode 169, initial_state (3, 22, 3), reward 968.0, memory_length 3000, epsilon 0.18112695312597027 total_time 725.0\n",
      "Episode  170\n",
      "Episode  171\n",
      "Episode  172\n",
      "Episode  173\n",
      "Episode  174\n",
      "Episode  175\n",
      "Episode  176\n",
      "Episode  177\n",
      "Episode  178\n",
      "Episode  179\n",
      "episode 179, initial_state (2, 4, 2), reward 1043.0, memory_length 3000, epsilon 0.16380796970808745 total_time 722.0\n",
      "Episode  180\n",
      "Episode  181\n",
      "Episode  182\n",
      "Episode  183\n",
      "Episode  184\n",
      "Episode  185\n",
      "Episode  186\n",
      "Episode  187\n",
      "Episode  188\n",
      "Episode  189\n",
      "episode 189, initial_state (4, 0, 5), reward 795.0, memory_length 3000, epsilon 0.1481449915475795 total_time 722.0\n",
      "Episode  190\n",
      "Episode  191\n",
      "Episode  192\n",
      "Episode  193\n",
      "Episode  194\n",
      "Episode  195\n",
      "Episode  196\n",
      "Episode  197\n",
      "Episode  198\n",
      "Episode  199\n",
      "episode 199, initial_state (0, 18, 4), reward 933.0, memory_length 3000, epsilon 0.13397967485796175 total_time 727.0\n",
      "Episode  200\n",
      "Episode  201\n",
      "Episode  202\n",
      "Episode  203\n",
      "Episode  204\n",
      "Episode  205\n",
      "Episode  206\n",
      "Episode  207\n",
      "Episode  208\n",
      "Episode  209\n",
      "episode 209, initial_state (2, 1, 3), reward 957.0, memory_length 3000, epsilon 0.1211688163570484 total_time 722.0\n",
      "Episode  210\n",
      "Episode  211\n",
      "Episode  212\n",
      "Episode  213\n",
      "Episode  214\n",
      "Episode  215\n",
      "Episode  216\n",
      "Episode  217\n",
      "Episode  218\n",
      "Episode  219\n",
      "episode 219, initial_state (3, 19, 5), reward 1018.0, memory_length 3000, epsilon 0.10958290556334822 total_time 727.0\n",
      "Episode  220\n",
      "Episode  221\n",
      "Episode  222\n",
      "Episode  223\n",
      "Episode  224\n",
      "Episode  225\n",
      "Episode  226\n",
      "Episode  227\n",
      "Episode  228\n",
      "Episode  229\n",
      "episode 229, initial_state (2, 12, 5), reward 1220.0, memory_length 3000, epsilon 0.09910481551887473 total_time 724.0\n",
      "Episode  230\n",
      "Episode  231\n",
      "Episode  232\n",
      "Episode  233\n",
      "Episode  234\n",
      "Episode  235\n",
      "Episode  236\n",
      "Episode  237\n",
      "Episode  238\n",
      "Episode  239\n",
      "episode 239, initial_state (4, 22, 2), reward 1338.0, memory_length 3000, epsilon 0.08962861870232469 total_time 730.0\n",
      "Episode  240\n",
      "Episode  241\n",
      "Episode  242\n",
      "Episode  243\n",
      "Episode  244\n",
      "Episode  245\n",
      "Episode  246\n",
      "Episode  247\n",
      "Episode  248\n",
      "Episode  249\n",
      "episode 249, initial_state (0, 1, 0), reward 933.0, memory_length 3000, epsilon 0.08105851616218133 total_time 728.0\n",
      "Episode  250\n",
      "Episode  251\n",
      "Episode  252\n",
      "Episode  253\n",
      "Episode  254\n",
      "Episode  255\n",
      "Episode  256\n",
      "Episode  257\n",
      "Episode  258\n",
      "Episode  259\n",
      "episode 259, initial_state (4, 6, 2), reward 972.0, memory_length 3000, epsilon 0.07330786904388827 total_time 723.0\n",
      "Episode  260\n",
      "Episode  261\n",
      "Episode  262\n",
      "Episode  263\n",
      "Episode  264\n",
      "Episode  265\n",
      "Episode  266\n",
      "Episode  267\n",
      "Episode  268\n",
      "Episode  269\n",
      "episode 269, initial_state (3, 20, 5), reward 1467.0, memory_length 3000, epsilon 0.06629832272038537 total_time 728.0\n",
      "Episode  270\n",
      "Episode  271\n",
      "Episode  272\n",
      "Episode  273\n",
      "Episode  274\n",
      "Episode  275\n",
      "Episode  276\n",
      "Episode  277\n",
      "Episode  278\n",
      "Episode  279\n",
      "episode 279, initial_state (4, 6, 6), reward 1104.0, memory_length 3000, epsilon 0.05995901467146548 total_time 723.0\n",
      "Episode  280\n",
      "Episode  281\n",
      "Episode  282\n",
      "Episode  283\n",
      "Episode  284\n",
      "Episode  285\n",
      "Episode  286\n",
      "Episode  287\n",
      "Episode  288\n",
      "Episode  289\n",
      "episode 289, initial_state (1, 19, 2), reward 1427.0, memory_length 3000, epsilon 0.054225858104063294 total_time 738.0\n",
      "Episode  290\n",
      "Episode  291\n",
      "Episode  292\n",
      "Episode  293\n",
      "Episode  294\n",
      "Episode  295\n",
      "Episode  296\n",
      "Episode  297\n",
      "Episode  298\n",
      "Episode  299\n",
      "episode 299, initial_state (3, 12, 3), reward 860.0, memory_length 3000, epsilon 0.04904089407128576 total_time 730.0\n",
      "Episode  300\n",
      "Episode  301\n",
      "Episode  302\n",
      "Episode  303\n",
      "Episode  304\n",
      "Episode  305\n",
      "Episode  306\n",
      "Episode  307\n",
      "Episode  308\n",
      "Episode  309\n",
      "episode 309, initial_state (3, 23, 2), reward 1393.0, memory_length 3000, epsilon 0.04435170554047638 total_time 722.0\n",
      "Episode  310\n",
      "Episode  311\n",
      "Episode  312\n",
      "Episode  313\n",
      "Episode  314\n",
      "Episode  315\n",
      "Episode  316\n",
      "Episode  317\n",
      "Episode  318\n",
      "Episode  319\n",
      "episode 319, initial_state (3, 22, 0), reward 1352.0, memory_length 3000, epsilon 0.04011088748687551 total_time 724.0\n",
      "Episode  320\n",
      "Episode  321\n",
      "Episode  322\n",
      "Episode  323\n",
      "Episode  324\n",
      "Episode  325\n",
      "Episode  326\n",
      "Episode  327\n",
      "Episode  328\n",
      "Episode  329\n",
      "episode 329, initial_state (1, 23, 4), reward 1268.0, memory_length 3000, epsilon 0.036275567655825146 total_time 721.0\n",
      "Episode  330\n",
      "Episode  331\n",
      "Episode  332\n",
      "Episode  333\n",
      "Episode  334\n",
      "Episode  335\n",
      "Episode  336\n",
      "Episode  337\n",
      "Episode  338\n",
      "Episode  339\n",
      "episode 339, initial_state (0, 6, 2), reward 1413.0, memory_length 3000, epsilon 0.03280697314869741 total_time 722.0\n",
      "Episode  340\n",
      "Episode  341\n",
      "Episode  342\n",
      "Episode  343\n",
      "Episode  344\n",
      "Episode  345\n",
      "Episode  346\n",
      "Episode  347\n",
      "Episode  348\n",
      "Episode  349\n",
      "episode 349, initial_state (2, 12, 2), reward 1338.0, memory_length 3000, epsilon 0.029670038450977095 total_time 725.0\n",
      "Episode  350\n",
      "Episode  351\n",
      "Episode  352\n",
      "Episode  353\n",
      "Episode  354\n",
      "Episode  355\n",
      "Episode  356\n",
      "Episode  357\n",
      "Episode  358\n",
      "Episode  359\n",
      "episode 359, initial_state (4, 9, 6), reward 1484.0, memory_length 3000, epsilon 0.026833050939885677 total_time 728.0\n",
      "Episode  360\n",
      "Episode  361\n",
      "Episode  362\n",
      "Episode  363\n",
      "Episode  364\n",
      "Episode  365\n",
      "Episode  366\n",
      "Episode  367\n",
      "Episode  368\n",
      "Episode  369\n",
      "episode 369, initial_state (1, 10, 1), reward 1463.0, memory_length 3000, epsilon 0.024267330287830756 total_time 721.0\n",
      "Episode  370\n",
      "Episode  371\n",
      "Episode  372\n",
      "Episode  373\n",
      "Episode  374\n",
      "Episode  375\n",
      "Episode  376\n",
      "Episode  377\n",
      "Episode  378\n",
      "Episode  379\n",
      "episode 379, initial_state (1, 22, 3), reward 1439.0, memory_length 3000, epsilon 0.02194693852063239 total_time 726.0\n",
      "Episode  380\n",
      "Episode  381\n",
      "Episode  382\n",
      "Episode  383\n",
      "Episode  384\n",
      "Episode  385\n",
      "Episode  386\n",
      "Episode  387\n",
      "Episode  388\n",
      "Episode  389\n",
      "episode 389, initial_state (1, 6, 1), reward 1786.0, memory_length 3000, epsilon 0.01984841779938018 total_time 723.0\n",
      "Episode  390\n",
      "Episode  391\n",
      "Episode  392\n",
      "Episode  393\n",
      "Episode  394\n",
      "Episode  395\n",
      "Episode  396\n",
      "Episode  397\n",
      "Episode  398\n",
      "Episode  399\n",
      "episode 399, initial_state (0, 23, 5), reward 1113.0, memory_length 3000, epsilon 0.017950553275045134 total_time 722.0\n",
      "Episode  400\n",
      "Episode  401\n",
      "Episode  402\n",
      "Episode  403\n",
      "Episode  404\n",
      "Episode  405\n",
      "Episode  406\n",
      "Episode  407\n",
      "Episode  408\n",
      "Episode  409\n",
      "episode 409, initial_state (1, 21, 3), reward 1293.0, memory_length 3000, epsilon 0.01623415861844141 total_time 727.0\n",
      "Episode  410\n",
      "Episode  411\n",
      "Episode  412\n",
      "Episode  413\n",
      "Episode  414\n",
      "Episode  415\n",
      "Episode  416\n",
      "Episode  417\n",
      "Episode  418\n",
      "Episode  419\n",
      "episode 419, initial_state (2, 22, 1), reward 1278.0, memory_length 3000, epsilon 0.014681882057368112 total_time 728.0\n",
      "Episode  420\n",
      "Episode  421\n",
      "Episode  422\n",
      "Episode  423\n",
      "Episode  424\n",
      "Episode  425\n",
      "Episode  426\n",
      "Episode  427\n",
      "Episode  428\n",
      "Episode  429\n",
      "episode 429, initial_state (2, 12, 6), reward 1270.0, memory_length 3000, epsilon 0.013278030960077106 total_time 724.0\n",
      "Episode  430\n",
      "Episode  431\n",
      "Episode  432\n",
      "Episode  433\n",
      "Episode  434\n",
      "Episode  435\n",
      "Episode  436\n",
      "Episode  437\n",
      "Episode  438\n",
      "Episode  439\n",
      "episode 439, initial_state (2, 3, 3), reward 1253.0, memory_length 3000, epsilon 0.01200841319170568 total_time 722.0\n",
      "Episode  440\n",
      "Episode  441\n",
      "Episode  442\n",
      "Episode  443\n",
      "Episode  444\n",
      "Episode  445\n",
      "Episode  446\n",
      "Episode  447\n",
      "Episode  448\n",
      "Episode  449\n",
      "episode 449, initial_state (4, 12, 5), reward 1603.0, memory_length 3000, epsilon 0.010860193639877886 total_time 728.0\n",
      "Episode  450\n",
      "Episode  451\n",
      "Episode  452\n",
      "Episode  453\n",
      "Episode  454\n",
      "Episode  455\n",
      "Episode  456\n",
      "Episode  457\n",
      "Episode  458\n",
      "Episode  459\n",
      "episode 459, initial_state (3, 11, 0), reward 1153.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  460\n",
      "Episode  461\n",
      "Episode  462\n",
      "Episode  463\n",
      "Episode  464\n",
      "Episode  465\n",
      "Episode  466\n",
      "Episode  467\n",
      "Episode  468\n",
      "Episode  469\n",
      "episode 469, initial_state (3, 11, 4), reward 1328.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  470\n",
      "Episode  471\n",
      "Episode  472\n",
      "Episode  473\n",
      "Episode  474\n",
      "Episode  475\n",
      "Episode  476\n",
      "Episode  477\n",
      "Episode  478\n",
      "Episode  479\n",
      "episode 479, initial_state (3, 20, 6), reward 1287.0, memory_length 3000, epsilon 0.009920974201040588 total_time 731.0\n",
      "Episode  480\n",
      "Episode  481\n",
      "Episode  482\n",
      "Episode  483\n",
      "Episode  484\n",
      "Episode  485\n",
      "Episode  486\n",
      "Episode  487\n",
      "Episode  488\n",
      "Episode  489\n",
      "episode 489, initial_state (1, 12, 1), reward 1620.0, memory_length 3000, epsilon 0.009920974201040588 total_time 727.0\n",
      "Episode  490\n",
      "Episode  491\n",
      "Episode  492\n",
      "Episode  493\n",
      "Episode  494\n",
      "Episode  495\n",
      "Episode  496\n",
      "Episode  497\n",
      "Episode  498\n",
      "Episode  499\n",
      "episode 499, initial_state (1, 21, 6), reward 1314.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  500\n",
      "Saving Episode 500 Weights\n",
      "Episode  501\n",
      "Episode  502\n",
      "Episode  503\n",
      "Episode  504\n",
      "Episode  505\n",
      "Episode  506\n",
      "Episode  507\n",
      "Episode  508\n",
      "Episode  509\n",
      "episode 509, initial_state (2, 21, 1), reward 1824.0, memory_length 3000, epsilon 0.009920974201040588 total_time 723.0\n",
      "Episode  510\n",
      "Episode  511\n",
      "Episode  512\n",
      "Episode  513\n",
      "Episode  514\n",
      "Episode  515\n",
      "Episode  516\n",
      "Episode  517\n",
      "Episode  518\n",
      "Episode  519\n",
      "episode 519, initial_state (4, 10, 3), reward 1450.0, memory_length 3000, epsilon 0.009920974201040588 total_time 729.0\n",
      "Episode  520\n",
      "Episode  521\n",
      "Episode  522\n",
      "Episode  523\n",
      "Episode  524\n",
      "Episode  525\n",
      "Episode  526\n",
      "Episode  527\n",
      "Episode  528\n",
      "Episode  529\n",
      "episode 529, initial_state (2, 3, 1), reward 1331.0, memory_length 3000, epsilon 0.009920974201040588 total_time 723.0\n",
      "Episode  530\n",
      "Episode  531\n",
      "Episode  532\n",
      "Episode  533\n",
      "Episode  534\n",
      "Episode  535\n",
      "Episode  536\n",
      "Episode  537\n",
      "Episode  538\n",
      "Episode  539\n",
      "episode 539, initial_state (3, 19, 4), reward 1411.0, memory_length 3000, epsilon 0.009920974201040588 total_time 723.0\n",
      "Episode  540\n",
      "Episode  541\n",
      "Episode  542\n",
      "Episode  543\n",
      "Episode  544\n",
      "Episode  545\n",
      "Episode  546\n",
      "Episode  547\n",
      "Episode  548\n",
      "Episode  549\n",
      "episode 549, initial_state (0, 17, 1), reward 1159.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  550\n",
      "Episode  551\n",
      "Episode  552\n",
      "Episode  553\n",
      "Episode  554\n",
      "Episode  555\n",
      "Episode  556\n",
      "Episode  557\n",
      "Episode  558\n",
      "Episode  559\n",
      "episode 559, initial_state (2, 22, 6), reward 1346.0, memory_length 3000, epsilon 0.009920974201040588 total_time 730.0\n",
      "Episode  560\n",
      "Episode  561\n",
      "Episode  562\n",
      "Episode  563\n",
      "Episode  564\n",
      "Episode  565\n",
      "Episode  566\n",
      "Episode  567\n",
      "Episode  568\n",
      "Episode  569\n",
      "episode 569, initial_state (4, 2, 4), reward 1016.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  570\n",
      "Episode  571\n",
      "Episode  572\n",
      "Episode  573\n",
      "Episode  574\n",
      "Episode  575\n",
      "Episode  576\n",
      "Episode  577\n",
      "Episode  578\n",
      "Episode  579\n",
      "episode 579, initial_state (2, 14, 0), reward 1241.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  580\n",
      "Episode  581\n",
      "Episode  582\n",
      "Episode  583\n",
      "Episode  584\n",
      "Episode  585\n",
      "Episode  586\n",
      "Episode  587\n",
      "Episode  588\n",
      "Episode  589\n",
      "episode 589, initial_state (1, 6, 4), reward 1454.0, memory_length 3000, epsilon 0.009920974201040588 total_time 727.0\n",
      "Episode  590\n",
      "Episode  591\n",
      "Episode  592\n",
      "Episode  593\n",
      "Episode  594\n",
      "Episode  595\n",
      "Episode  596\n",
      "Episode  597\n",
      "Episode  598\n",
      "Episode  599\n",
      "episode 599, initial_state (0, 13, 3), reward 1435.0, memory_length 3000, epsilon 0.009920974201040588 total_time 723.0\n",
      "Episode  600\n",
      "Episode  601\n",
      "Episode  602\n",
      "Episode  603\n",
      "Episode  604\n",
      "Episode  605\n",
      "Episode  606\n",
      "Episode  607\n",
      "Episode  608\n",
      "Episode  609\n",
      "episode 609, initial_state (2, 7, 5), reward 1319.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  610\n",
      "Episode  611\n",
      "Episode  612\n",
      "Episode  613\n",
      "Episode  614\n",
      "Episode  615\n",
      "Episode  616\n",
      "Episode  617\n",
      "Episode  618\n",
      "Episode  619\n",
      "episode 619, initial_state (2, 19, 0), reward 1015.0, memory_length 3000, epsilon 0.009920974201040588 total_time 727.0\n",
      "Episode  620\n",
      "Episode  621\n",
      "Episode  622\n",
      "Episode  623\n",
      "Episode  624\n",
      "Episode  625\n",
      "Episode  626\n",
      "Episode  627\n",
      "Episode  628\n",
      "Episode  629\n",
      "episode 629, initial_state (2, 10, 5), reward 1296.0, memory_length 3000, epsilon 0.009920974201040588 total_time 724.0\n",
      "Episode  630\n",
      "Episode  631\n",
      "Episode  632\n",
      "Episode  633\n",
      "Episode  634\n",
      "Episode  635\n",
      "Episode  636\n",
      "Episode  637\n",
      "Episode  638\n",
      "Episode  639\n",
      "episode 639, initial_state (0, 8, 6), reward 1286.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  640\n",
      "Episode  641\n",
      "Episode  642\n",
      "Episode  643\n",
      "Episode  644\n",
      "Episode  645\n",
      "Episode  646\n",
      "Episode  647\n",
      "Episode  648\n",
      "Episode  649\n",
      "episode 649, initial_state (1, 20, 0), reward 1161.0, memory_length 3000, epsilon 0.009920974201040588 total_time 728.0\n",
      "Episode  650\n",
      "Episode  651\n",
      "Episode  652\n",
      "Episode  653\n",
      "Episode  654\n",
      "Episode  655\n",
      "Episode  656\n",
      "Episode  657\n",
      "Episode  658\n",
      "Episode  659\n",
      "episode 659, initial_state (2, 23, 2), reward 1029.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  660\n",
      "Episode  661\n",
      "Episode  662\n",
      "Episode  663\n",
      "Episode  664\n",
      "Episode  665\n",
      "Episode  666\n",
      "Episode  667\n",
      "Episode  668\n",
      "Episode  669\n",
      "episode 669, initial_state (3, 14, 6), reward 1530.0, memory_length 3000, epsilon 0.009920974201040588 total_time 726.0\n",
      "Episode  670\n",
      "Episode  671\n",
      "Episode  672\n",
      "Episode  673\n",
      "Episode  674\n",
      "Episode  675\n",
      "Episode  676\n",
      "Episode  677\n",
      "Episode  678\n",
      "Episode  679\n",
      "episode 679, initial_state (4, 2, 4), reward 1300.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  680\n",
      "Episode  681\n",
      "Episode  682\n",
      "Episode  683\n",
      "Episode  684\n",
      "Episode  685\n",
      "Episode  686\n",
      "Episode  687\n",
      "Episode  688\n",
      "Episode  689\n",
      "episode 689, initial_state (3, 23, 2), reward 1105.0, memory_length 3000, epsilon 0.009920974201040588 total_time 725.0\n",
      "Episode  690\n",
      "Episode  691\n",
      "Episode  692\n",
      "Episode  693\n",
      "Episode  694\n",
      "Episode  695\n",
      "Episode  696\n",
      "Episode  697\n",
      "Episode  698\n",
      "Episode  699\n",
      "episode 699, initial_state (3, 2, 4), reward 1440.0, memory_length 3000, epsilon 0.009920974201040588 total_time 727.0\n",
      "Episode  700\n",
      "Episode  701\n",
      "Episode  702\n",
      "Episode  703\n",
      "Episode  704\n",
      "Episode  705\n",
      "Episode  706\n",
      "Episode  707\n",
      "Episode  708\n",
      "Episode  709\n",
      "episode 709, initial_state (0, 6, 4), reward 1394.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  710\n",
      "Episode  711\n",
      "Episode  712\n",
      "Episode  713\n",
      "Episode  714\n",
      "Episode  715\n",
      "Episode  716\n",
      "Episode  717\n",
      "Episode  718\n",
      "Episode  719\n",
      "episode 719, initial_state (2, 20, 0), reward 1626.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  720\n",
      "Episode  721\n",
      "Episode  722\n",
      "Episode  723\n",
      "Episode  724\n",
      "Episode  725\n",
      "Episode  726\n",
      "Episode  727\n",
      "Episode  728\n",
      "Episode  729\n",
      "episode 729, initial_state (1, 21, 0), reward 817.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  730\n",
      "Episode  731\n",
      "Episode  732\n",
      "Episode  733\n",
      "Episode  734\n",
      "Episode  735\n",
      "Episode  736\n",
      "Episode  737\n",
      "Episode  738\n",
      "Episode  739\n",
      "episode 739, initial_state (4, 2, 6), reward 1477.0, memory_length 3000, epsilon 0.009920974201040588 total_time 724.0\n",
      "Episode  740\n",
      "Episode  741\n",
      "Episode  742\n",
      "Episode  743\n",
      "Episode  744\n",
      "Episode  745\n",
      "Episode  746\n",
      "Episode  747\n",
      "Episode  748\n",
      "Episode  749\n",
      "episode 749, initial_state (2, 4, 2), reward 1509.0, memory_length 3000, epsilon 0.009920974201040588 total_time 723.0\n",
      "Episode  750\n",
      "Episode  751\n",
      "Episode  752\n",
      "Episode  753\n",
      "Episode  754\n",
      "Episode  755\n",
      "Episode  756\n",
      "Episode  757\n",
      "Episode  758\n",
      "Episode  759\n",
      "episode 759, initial_state (2, 21, 6), reward 1220.0, memory_length 3000, epsilon 0.009920974201040588 total_time 725.0\n",
      "Episode  760\n",
      "Episode  761\n",
      "Episode  762\n",
      "Episode  763\n",
      "Episode  764\n",
      "Episode  765\n",
      "Episode  766\n",
      "Episode  767\n",
      "Episode  768\n",
      "Episode  769\n",
      "episode 769, initial_state (1, 0, 2), reward 1207.0, memory_length 3000, epsilon 0.009920974201040588 total_time 727.0\n",
      "Episode  770\n",
      "Episode  771\n",
      "Episode  772\n",
      "Episode  773\n",
      "Episode  774\n",
      "Episode  775\n",
      "Episode  776\n",
      "Episode  777\n",
      "Episode  778\n",
      "Episode  779\n",
      "episode 779, initial_state (3, 7, 5), reward 1223.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  780\n",
      "Episode  781\n",
      "Episode  782\n",
      "Episode  783\n",
      "Episode  784\n",
      "Episode  785\n",
      "Episode  786\n",
      "Episode  787\n",
      "Episode  788\n",
      "Episode  789\n",
      "episode 789, initial_state (3, 17, 0), reward 1357.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  790\n",
      "Episode  791\n",
      "Episode  792\n",
      "Episode  793\n",
      "Episode  794\n",
      "Episode  795\n",
      "Episode  796\n",
      "Episode  797\n",
      "Episode  798\n",
      "Episode  799\n",
      "episode 799, initial_state (3, 21, 1), reward 1440.0, memory_length 3000, epsilon 0.009920974201040588 total_time 726.0\n",
      "Episode  800\n",
      "Episode  801\n",
      "Episode  802\n",
      "Episode  803\n",
      "Episode  804\n",
      "Episode  805\n",
      "Episode  806\n",
      "Episode  807\n",
      "Episode  808\n",
      "Episode  809\n",
      "episode 809, initial_state (4, 5, 4), reward 1343.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  810\n",
      "Episode  811\n",
      "Episode  812\n",
      "Episode  813\n",
      "Episode  814\n",
      "Episode  815\n",
      "Episode  816\n",
      "Episode  817\n",
      "Episode  818\n",
      "Episode  819\n",
      "episode 819, initial_state (2, 22, 0), reward 880.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  820\n",
      "Episode  821\n",
      "Episode  822\n",
      "Episode  823\n",
      "Episode  824\n",
      "Episode  825\n",
      "Episode  826\n",
      "Episode  827\n",
      "Episode  828\n",
      "Episode  829\n",
      "episode 829, initial_state (0, 0, 1), reward 1315.0, memory_length 3000, epsilon 0.009920974201040588 total_time 724.0\n",
      "Episode  830\n",
      "Episode  831\n",
      "Episode  832\n",
      "Episode  833\n",
      "Episode  834\n",
      "Episode  835\n",
      "Episode  836\n",
      "Episode  837\n",
      "Episode  838\n",
      "Episode  839\n",
      "episode 839, initial_state (0, 5, 2), reward 1337.0, memory_length 3000, epsilon 0.009920974201040588 total_time 730.0\n",
      "Episode  840\n",
      "Episode  841\n",
      "Episode  842\n",
      "Episode  843\n",
      "Episode  844\n",
      "Episode  845\n",
      "Episode  846\n",
      "Episode  847\n",
      "Episode  848\n",
      "Episode  849\n",
      "episode 849, initial_state (3, 3, 0), reward 1229.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  850\n",
      "Episode  851\n",
      "Episode  852\n",
      "Episode  853\n",
      "Episode  854\n",
      "Episode  855\n",
      "Episode  856\n",
      "Episode  857\n",
      "Episode  858\n",
      "Episode  859\n",
      "episode 859, initial_state (4, 13, 6), reward 1664.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  860\n",
      "Episode  861\n",
      "Episode  862\n",
      "Episode  863\n",
      "Episode  864\n",
      "Episode  865\n",
      "Episode  866\n",
      "Episode  867\n",
      "Episode  868\n",
      "Episode  869\n",
      "episode 869, initial_state (0, 3, 4), reward 1605.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  870\n",
      "Episode  871\n",
      "Episode  872\n",
      "Episode  873\n",
      "Episode  874\n",
      "Episode  875\n",
      "Episode  876\n",
      "Episode  877\n",
      "Episode  878\n",
      "Episode  879\n",
      "episode 879, initial_state (2, 9, 3), reward 1728.0, memory_length 3000, epsilon 0.009920974201040588 total_time 724.0\n",
      "Episode  880\n",
      "Episode  881\n",
      "Episode  882\n",
      "Episode  883\n",
      "Episode  884\n",
      "Episode  885\n",
      "Episode  886\n",
      "Episode  887\n",
      "Episode  888\n",
      "Episode  889\n",
      "episode 889, initial_state (2, 8, 4), reward 1448.0, memory_length 3000, epsilon 0.009920974201040588 total_time 726.0\n",
      "Episode  890\n",
      "Episode  891\n",
      "Episode  892\n",
      "Episode  893\n",
      "Episode  894\n",
      "Episode  895\n",
      "Episode  896\n",
      "Episode  897\n",
      "Episode  898\n",
      "Episode  899\n",
      "episode 899, initial_state (1, 16, 3), reward 1769.0, memory_length 3000, epsilon 0.009920974201040588 total_time 727.0\n",
      "Episode  900\n",
      "Episode  901\n",
      "Episode  902\n",
      "Episode  903\n",
      "Episode  904\n",
      "Episode  905\n",
      "Episode  906\n",
      "Episode  907\n",
      "Episode  908\n",
      "Episode  909\n",
      "episode 909, initial_state (4, 17, 3), reward 1589.0, memory_length 3000, epsilon 0.009920974201040588 total_time 727.0\n",
      "Episode  910\n",
      "Episode  911\n",
      "Episode  912\n",
      "Episode  913\n",
      "Episode  914\n",
      "Episode  915\n",
      "Episode  916\n",
      "Episode  917\n",
      "Episode  918\n",
      "Episode  919\n",
      "episode 919, initial_state (1, 19, 5), reward 1382.0, memory_length 3000, epsilon 0.009920974201040588 total_time 731.0\n",
      "Episode  920\n",
      "Episode  921\n",
      "Episode  922\n",
      "Episode  923\n",
      "Episode  924\n",
      "Episode  925\n",
      "Episode  926\n",
      "Episode  927\n",
      "Episode  928\n",
      "Episode  929\n",
      "episode 929, initial_state (2, 0, 5), reward 1684.0, memory_length 3000, epsilon 0.009920974201040588 total_time 721.0\n",
      "Episode  930\n",
      "Episode  931\n",
      "Episode  932\n",
      "Episode  933\n",
      "Episode  934\n",
      "Episode  935\n",
      "Episode  936\n",
      "Episode  937\n",
      "Episode  938\n",
      "Episode  939\n",
      "episode 939, initial_state (0, 14, 3), reward 1503.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  940\n",
      "Episode  941\n",
      "Episode  942\n",
      "Episode  943\n",
      "Episode  944\n",
      "Episode  945\n",
      "Episode  946\n",
      "Episode  947\n",
      "Episode  948\n",
      "Episode  949\n",
      "episode 949, initial_state (0, 0, 4), reward 1351.0, memory_length 3000, epsilon 0.009920974201040588 total_time 724.0\n",
      "Episode  950\n",
      "Episode  951\n",
      "Episode  952\n",
      "Episode  953\n",
      "Episode  954\n",
      "Episode  955\n",
      "Episode  956\n",
      "Episode  957\n",
      "Episode  958\n",
      "Episode  959\n",
      "episode 959, initial_state (3, 8, 0), reward 1493.0, memory_length 3000, epsilon 0.009920974201040588 total_time 722.0\n",
      "Episode  960\n",
      "Episode  961\n",
      "Episode  962\n",
      "Episode  963\n",
      "Episode  964\n",
      "Episode  965\n",
      "Episode  966\n",
      "Episode  967\n",
      "Episode  968\n",
      "Episode  969\n",
      "episode 969, initial_state (2, 23, 6), reward 1347.0, memory_length 3000, epsilon 0.009920974201040588 total_time 724.0\n",
      "Episode  970\n",
      "Episode  971\n",
      "Episode  972\n",
      "Episode  973\n",
      "Episode  974\n",
      "Episode  975\n",
      "Episode  976\n",
      "Episode  977\n",
      "Episode  978\n",
      "Episode  979\n",
      "episode 979, initial_state (0, 0, 0), reward 1114.0, memory_length 3000, epsilon 0.009920974201040588 total_time 726.0\n",
      "Episode  980\n",
      "Episode  981\n",
      "Episode  982\n",
      "Episode  983\n",
      "Episode  984\n",
      "Episode  985\n",
      "Episode  986\n",
      "Episode  987\n",
      "Episode  988\n",
      "Episode  989\n",
      "episode 989, initial_state (2, 20, 0), reward 1310.0, memory_length 3000, epsilon 0.009920974201040588 total_time 726.0\n",
      "Episode  990\n",
      "Episode  991\n",
      "Episode  992\n",
      "Episode  993\n",
      "Episode  994\n",
      "Episode  995\n",
      "Episode  996\n",
      "Episode  997\n",
      "Episode  998\n",
      "Episode  999\n",
      "episode 999, initial_state (1, 3, 6), reward 1486.0, memory_length 3000, epsilon 0.009920974201040588 total_time 733.0\n",
      "17435.1179561615\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "score_tracked = []\n",
    "\n",
    "for episode in range(Episodes):\n",
    "    print('Episode ', episode)\n",
    "\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    # Reset at the start of each episode\n",
    "    env = CabDriver()\n",
    "    action_space, state_space, state = env.reset()\n",
    "    # State Initialization \n",
    "    initial_state = state\n",
    "\n",
    "\n",
    "    total_time = 0  # Total time driver rode in this episode\n",
    "    while done!= True:\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state.\n",
    "        action= agent.get_action(state)\n",
    "        \n",
    "        # 2. Evaluate reward and next state\n",
    "        next_state, reward, step_time = env.step(state, env.action_space[action], Time_matrix)\n",
    "        \n",
    "        # 3. Total time driver rode in this episode\n",
    "        total_time += step_time\n",
    "        if (total_time > episode_time):\n",
    "            done = True\n",
    "        else:\n",
    "            # 4. Append the experience to the memory\n",
    "            agent.append_sample(state, action, reward, next_state, done)   ## Note: Here action is action index\n",
    "            \n",
    "            # 5. Train the model by calling function agent.train_model\n",
    "            agent.train_model()\n",
    "            \n",
    "            # 6. Keep a track of rewards, Q-values, loss, etc (Note: Loss is taken care of in the model loss='mse')\n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "    # Store total reward obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "    \n",
    "\n",
    "    # epsilon decay\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon *= agent.epsilon_decay\n",
    "\n",
    "\n",
    "    # Every 1000 episodes we will print:\n",
    "    if ((episode + 1) % 10 == 0):\n",
    "        print(\"episode {0}, initial_state {1}, reward {2}, memory_length {3}, epsilon {4} total_time {5}\".format(episode, \n",
    "                                                                         initial_state,\n",
    "                                                                         score,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon, total_time))\n",
    "    \n",
    "    # Save the Q_value of the state-action pair we are tracking (every 10 episodes)\n",
    "    if ((episode + 1) % 10 == 0):\n",
    "        agent.save_tracking_states()\n",
    "\n",
    "    # Total rewards per episode\n",
    "    score_tracked.append(score)\n",
    "\n",
    "    ## Saving the 'model_weights' every 1000th episode.\n",
    "    if(episode % 500 == 0):\n",
    "        print(\"Saving Episode {} Weights\".format(episode))\n",
    "#         agent.save_model_weights(name=\"model_weights\")  \n",
    "        agent.save_weights_numpy(name = f'model_weights_{episode}.pkl')\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have allowed the agent to play in the environment though 1000 episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we look at the rewards the agent collects upon completing an episode, the rewards in the initial episodes, it is very low around few hundreds, but towards end of training the reward collectd by our agent is 1600. It shows that the agent is learning to learn a policy that will yield maximum profits in any givent initial state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkHAFwizlWSm"
   },
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZhKKatIQlWSm"
   },
   "outputs": [],
   "source": [
    "def convergence_graph_q_val(fig_num, state, action, states_tracked):\n",
    "    plt.figure(fig_num, figsize=(10,4))\n",
    "    plt.title(f\"Convergence of Q_values for state {state} and action {action}\", fontsize=14, fontweight='bold')\n",
    "    xaxis = np.asarray(range(0, len(states_tracked)))\n",
    "    plt.plot(xaxis,np.asarray(states_tracked))\n",
    "    plt.ylabel(\"Q_values\")\n",
    "    plt.xlabel(\"No. of Episodes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "HfzJq4ialWSn",
    "outputId": "43c74937-4b33-42f4-a861-2153ad4d39db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking Convergence for state-action pair: State (2,8,6), Action (2,3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Tracking Convergence for state-action pair: State (2,8,6), Action (2,3)\\n\")\n",
    "convergence_graph_q_val(fig_num=1, \n",
    "                        state=(2,8,6), \n",
    "                        action=(2,3), \n",
    "                        states_tracked = agent.states_tracked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lieeDoQzZqhX"
   },
   "source": [
    "#### From the graph we can observed that state (2,8,6) stabalizes as the agent plays more episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The fluctuations in the Q values have reduced with more number of episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3boeLktOZV9X"
   },
   "source": [
    "## Epsilon decay function used for choosing an epsilon-greedy action during episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6RgOU6ETlWSo"
   },
   "outputs": [],
   "source": [
    "time = np.arange(0,1000) ## In all 1000 episodes. \n",
    "epsilon_decay = 0.99\n",
    "epsilon = 1\n",
    "\n",
    "epsilon_decayed = []\n",
    "epsilon_decayed.append(epsilon)\n",
    "\n",
    "for i in time:\n",
    "    new_epsilon = epsilon_decayed[i] * epsilon_decay\n",
    "    epsilon_decayed.append(new_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "HpiBCQ08lWSo",
    "outputId": "f3607e8b-a307-455f-b9c1-6ee4dfbe4e1d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon_decayed[:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bYIRBL9lWSp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrHBdPvilWSp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGu1fR5UlWSp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaI7FSS3lWSp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hgo5V4RclWSq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DQN_Agent_Arch1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
